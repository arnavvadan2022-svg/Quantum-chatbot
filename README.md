# ğŸ¤– Quantum RAG Chatbot

A powerful Retrieval-Augmented Generation (RAG) chatbot that combines document retrieval with AI-powered responses to provide intelligent, context-aware answers based on your knowledge base.

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Architecture](#architecture)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Configuration](#configuration)
- [How It Works](#how-it-works)
- [API Endpoints](#api-endpoints)
- [Contributing](#contributing)
- [License](#license)

## âœ¨ Features

- **Document Ingestion**: Upload and process various document formats (PDF, TXT, DOCX, etc.)
- **Vector Storage**: Efficient document embedding and storage using vector databases
- **Semantic Search**: Find relevant information using semantic similarity
- **Context-Aware Responses**: Generate accurate answers based on retrieved context
- **Conversational Interface**: Natural language interaction with chat history
- **REST API**: Easy integration with web and mobile applications
- **Scalable Architecture**: Built to handle large document collections

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web Interface  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Flask API Server  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vector â”‚ â”‚ LLM Provider â”‚
â”‚  DB    â”‚ â”‚ (OpenAI/etc) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Prerequisites

- Python 3.8 or higher
- pip (Python package manager)
- Virtual environment (recommended)
- API keys for LLM provider (OpenAI, Anthropic, etc.)

## ğŸš€ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/arnavvadan2022-svg/Quantum-chatbot.git
cd Quantum-chatbot
```

### 2. Create Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Set Up Environment Variables

Create a `.env` file in the root directory:

```env
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
VECTOR_DB_PATH=./data/vectordb
UPLOAD_FOLDER=./uploads
MAX_CONTENT_LENGTH=16777216
```

### 5. Initialize the Database

```bash
python init_db.py
```

## ğŸ’» Usage

### Running the Application

```bash
# Start the Flask server
python app.py

# The server will start on http://localhost:5000
```

### Using the Chatbot

1. **Upload Documents**:
   ```bash
   curl -X POST -F "file=@document.pdf" http://localhost:5000/upload
   ```

2. **Ask Questions**:
   ```bash
   curl -X POST -H "Content-Type: application/json" \
        -d '{"question": "What is quantum computing?"}' \
        http://localhost:5000/chat
   ```

3. **Web Interface**:
   - Open your browser and navigate to `http://localhost:5000`
   - Upload documents using the web interface
   - Start chatting with your documents

## ğŸ“ Project Structure

```
Quantum-chatbot/
â”‚
â”œâ”€â”€ app.py                  # Main Flask application
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env                    # Environment variables (create this)
â”œâ”€â”€ .gitignore             # Git ignore file
â”‚
â”œâ”€â”€ models/                 # ML models and embeddings
â”‚   â”œâ”€â”€ embeddings.py      # Document embedding logic
â”‚   â””â”€â”€ llm.py             # LLM integration
â”‚
â”œâ”€â”€ data/                   # Data storage
â”‚   â”œâ”€â”€ vectordb/          # Vector database storage
â”‚   â””â”€â”€ documents/         # Processed documents
â”‚
â”œâ”€â”€ uploads/               # Temporary upload directory
â”‚
â”œâ”€â”€ utils/                 # Utility functions
â”‚   â”œâ”€â”€ document_processor.py  # Document parsing
â”‚   â”œâ”€â”€ vector_store.py        # Vector DB operations
â”‚   â””â”€â”€ helpers.py             # Helper functions
â”‚
â”œâ”€â”€ static/                # Static files (CSS, JS)
â”‚   â”œâ”€â”€ css/
â”‚   â””â”€â”€ js/
â”‚
â”œâ”€â”€ templates/             # HTML templates
â”‚   â””â”€â”€ index.html
â”‚
â””â”€â”€ tests/                 # Unit tests
    â”œâ”€â”€ test_embeddings.py
    â””â”€â”€ test_api.py
```

## âš™ï¸ Configuration

### requirements.txt

```txt
flask==3.0.0
langchain==0.1.0
langchain-community==0.0.10
openai==1.6.1
anthropic==0.8.1
chromadb==0.4.22
sentence-transformers==2.2.2
PyPDF2==3.0.1
python-docx==1.1.0
python-dotenv==1.0.0
tiktoken==0.5.2
faiss-cpu==1.7.4
numpy==1.24.3
pandas==2.0.3
```

### Supported Document Formats

- PDF (`.pdf`)
- Text files (`.txt`)
- Word documents (`.docx`)
- Markdown (`.md`)
- CSV (`.csv`)

## ğŸ” How It Works

### 1. Document Ingestion
```python
# Documents are uploaded and processed
document â†’ text extraction â†’ chunking â†’ embedding
```

### 2. Vector Storage
```python
# Embeddings are stored in vector database
text_chunks â†’ embeddings â†’ vector_db
```

### 3. Question Answering
```python
# User question is processed
question â†’ embedding â†’ similarity_search â†’ context_retrieval â†’ LLM â†’ answer
```

### 4. RAG Pipeline
1. **Retrieve**: Find relevant document chunks using semantic search
2. **Augment**: Add retrieved context to the user's question
3. **Generate**: Use LLM to generate a contextual answer

## ğŸ”Œ API Endpoints

### POST /upload
Upload a document to the knowledge base.

**Request**:
```bash
curl -X POST -F "file=@document.pdf" http://localhost:5000/upload
```

**Response**:
```json
{
  "status": "success",
  "message": "Document uploaded and processed",
  "document_id": "abc123"
}
```

### POST /chat
Ask a question to the chatbot.

**Request**:
```json
{
  "question": "What is quantum computing?",
  "conversation_id": "optional-conv-id"
}
```

**Response**:
```json
{
  "answer": "Quantum computing is...",
  "sources": ["doc1.pdf", "doc2.pdf"],
  "conversation_id": "conv-123"
}
```

### GET /documents
List all uploaded documents.

**Response**:
```json
{
  "documents": [
    {
      "id": "doc1",
      "filename": "quantum.pdf",
      "uploaded_at": "2025-11-08T15:21:12Z"
    }
  ]
}
```

### DELETE /documents/:id
Delete a document from the knowledge base.

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- LangChain for the RAG framework
- OpenAI for language models
- ChromaDB for vector storage
- Flask for the web framework

## ğŸ“§ Contact

**Arnav Vadan** - [@arnavvadan2022-svg](https://github.com/arnavvadan2022-svg)

Project Link: [https://github.com/arnavvadan2022-svg/Quantum-chatbot](https://github.com/arnavvadan2022-svg/Quantum-chatbot)

---

Made with â¤ï¸ by Arnav Vadan
```
